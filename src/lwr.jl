# ------------------------------------------------------------------
# Licensed under the MIT License. See LICENCE in the project root.
# ------------------------------------------------------------------

"""
    LWR(varâ‚=>paramâ‚, varâ‚‚=>paramâ‚‚, ...)

Locally weighted regression estimation solver.

## Parameters

* `weightfun` - Weighting function (default to `exp(-h^2/2)`)
* `distance`  - A distance from Distances.jl (default to `Euclidean()`)
* `neighbors` - Number of neighbors (default to 20% of the data)

### References

* Stone 1977. *Consistent non-parametric regression.*
* Cleveland 1979. *Robust locally weighted regression and smoothing scatterplots.*
* Cleveland & Grosse 1991. *Computational methods for local regression.*
"""
@estimsolver LWR begin
  @param weightfun = h -> exp(-3*h^2)
  @param distance = Euclidean()
  @param neighbors = nothing
end

function solve(problem::EstimationProblem, solver::LWR)
  # retrieve problem info
  pdata = data(problem)
  pdomain = domain(problem)
  N = ncoords(pdomain)
  T = coordtype(pdomain)

  mactypeof = Dict(name(v) => mactype(v) for v in variables(problem))

  # result for each variable
  Î¼s = []; Ïƒs = []

  for covars in covariables(problem, solver)
    for var in covars.names
      # get user parameters
      varparams = covars.params[(var,)]

      # determine value type
      V = mactypeof[var]

      # retrieve non-missing data
      locs = findall(!ismissing, pdata[var])
      ğ’Ÿ = view(pdata, locs)
      X = coordinates(ğ’Ÿ)
      z = ğ’Ÿ[var]

      # number of data points for variable
      ndata = length(z)

      # weight function
      w = varparams.weightfun

      # number of nearest neighbors
      k = isnothing(varparams.neighbors) ? ceil(Int, 0.2ndata) : varparams.neighbors

      @assert 0 < k â‰¤ ndata "invalid number of neighbors"

      # fit search tree
      M = varparams.distance
      if M isa NearestNeighbors.MinkowskiMetric
        tree = KDTree(X, M)
      else
        tree = BallTree(X, M)
      end

      # pre-allocate memory for results
      varÎ¼ = Vector{V}(undef, nelms(pdomain))
      varÏƒ = Vector{V}(undef, nelms(pdomain))

      # pre-allocate memory for coordinates
      x = MVector{N,T}(undef)

      # estimation loop
      for loc in traverse(pdomain, LinearPath())
        coordinates!(x, pdomain, loc)

        # find neighbors
        is, ds = knn(tree, x, k)
        Î´s = ds ./ maximum(ds)

        # weighted least-squares
        Wâ‚— = Diagonal(w.(Î´s))
        Xâ‚— = [ones(eltype(X), k) X[:,is]']
        zâ‚— = view(z, is)
        Î¸â‚— = Xâ‚—'*Wâ‚—*Xâ‚— \ Xâ‚—'*Wâ‚—*zâ‚—

        # linear combination of response values
        xâ‚’ = [one(eltype(x)); x]
        zÌ‚â‚’ = Î¸â‚— â‹… xâ‚’
        râ‚— = Wâ‚—*Xâ‚—*(Xâ‚—'*Wâ‚—*Xâ‚—\xâ‚’)
        rÌ‚â‚’ = norm(râ‚—)

        varÎ¼[loc] = zÌ‚â‚’
        varÏƒ[loc] = rÌ‚â‚’
      end

      push!(Î¼s, var => varÎ¼)
      push!(Ïƒs, var => varÏƒ)
    end
  end

  EstimationSolution(pdomain, Dict(Î¼s), Dict(Ïƒs))
end
